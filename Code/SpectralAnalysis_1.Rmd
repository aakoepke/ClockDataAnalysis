---
title: "Multitaper Spectral Analysis on Data with Dead Time"
output: html_document
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(arfima)
library(tidyverse)
library(fields)
library(multitaper)
library(geigen)
library(RSpectra)
library(R.utils)
#functions:
h.k.prime <- function(k,N,N.prime){
  t <- 0:(N-1)
  h.k.N <- (2/(N+1))^(1/2)*sin((k + 1)*pi*(t + 1)/(N + 1)) #value of h' taper for t = 0, .., N-1
  if(N.prime > N){
    return(c(h.k.N, rep(0, times = N.prime-N)))#add in the 0's to pad the end to get up to 4096
  }
  else{
    return(h.k.N)
  }
}

avar_fn=function(y,tau){
  n=length(y)
  
  div=seq(1,n,by = tau)
  
  M=length(div)-1 #number of groups
  
  groupmeans = numeric(M)
  for(i in 1:M){
    groupmeans[i]=mean(y[div[i]:(div[i+1]-1)])
  }
  
  1/(2*(M-1)) * sum(diff(groupmeans)^2)
}

getAvars=function(N, y){
  taus = 2^(0:5)
  
  avars=numeric(length(taus))
  
  for (i in 1:length(taus)){
    avars[i]=avar_fn(y,taus[i])
  }
  
  m1=data.frame(taus=taus,avars=avars)  
  fit=lm(log(sqrt(avars))~log(taus),data = m1)
  slope=as.numeric(fit$coefficients[2])
  int=as.numeric(fit$coefficients[1])
  
  avarRes=data.frame(taus=taus,avars=avars,N=N,slope=slope,int=int)  
  
  ##########################################
  # get SE
  ##########################################
  SEests=data.frame()
  
  new=data.frame(N=N,out=exp(int+slope*log(N)), type="AD")
  new2=data.frame(N=N,out=sd(y)/sqrt(N), type="SE")
  new3=data.frame(N=N,out=1/sqrt(N), type="true")
  SEests=bind_rows(new,new2,new3)
  
  return(list(avarRes=avarRes,SEests=SEests))
}

```

## The Data

First we show an example of data generated from an ARFIMA(0,d,0) process with d = 0.4.

This process follows:

$$\nabla^d X_t = \epsilon_t$$


where we let $d = 0.4$ and $var\{\epsilon_t\} = 1$. We show the full process and the dead time process where there are chunks of the data removed.

```{r, echo = FALSE}
N <- 2048
d <- 0.4
X.t <- X.t_missing <- arfima.sim(N,model = list(dfrac = d))

endpoints <- c(450,700,1000,1200)#end points of missing chunks

X.t_missing[c(endpoints[1]:endpoints[2], endpoints[3]:endpoints[4])] <- NA


plot(X.t,type = "l", main = "Full Data", ylab = "X(t)", xlab = "t")
plot(X.t_missing,type = "l", main = "Partial Data", ylab = "X(t)", xlab = "t")
```




## Mutltitaper Spectral Estimate (MTSE)

We find the MTSE of the full and partial data using K = 6 tapers


```{r,echo = FALSE}
f.nyquist <- 1/2
f.j <- seq(0,f.nyquist, length.out = N)
X.tilde.prime <- X.t - mean(X.t)
t <- 0:(N-1)
S.x.hat <- rep(NA, times = N) #where S_x.hat(f'_j) will be saved

for(j in 0:(N-1)){
  k.vec <- rep(NA,times = 6)
  for(k in 0:5){
    W.t <- h.k.prime(k = k, N=N, N.prime = N)*X.tilde.prime
    inner.sum <- sum(W.t*exp(-complex(real = 0, imaginary = 1)*2*pi*t*j/N))
    k.vec[k + 1] <- abs(inner.sum)^2
  }
  S.x.hat[j+1] <- (1/length(k.vec))*sum(k.vec)
}

plot(log10(f.j), log10(S.x.hat), type = "l", main = "Full Data") #plot of multitaper spectral estimator

```



```{r, echo=FALSE}

t.n <- 1:N
t.n <- t.n[-c(endpoints[1]:endpoints[2], endpoints[3]:endpoints[4])]
NW <- 5
W <- NW/length(t.n)
dist.mat <- rdist(t.n)
K = 6 #number of sequences we want

#create the A' matrix (Chave 2019 equation (22))
A.prime <- (1/(pi*dist.mat))*sin(2*pi*W*dist.mat)
A.prime[row(A.prime) == col(A.prime)] <- W*2
eigdec <- eigs_sym(A.prime, k = K, which = "LM")


eig_vecs <- eigdec$vectors #get only the vectors

#some sign maintenance
    for(i in seq(1,K,by = 2)){
      if (mean(Re(eig_vecs[,i]))<0){
        eig_vecs[,i] <- -eig_vecs[,i]
      }
    }
    
    for(i in seq(2,K-1,by = 2)){
      if (Re(eig_vecs[2,i] - eig_vecs[1,i])<0){
        eig_vecs[,i] <- -eig_vecs[,i]
      }
    }


##use tapers to generate spectral estimate
t.n <- 1:N
t.n[c(endpoints[1]:endpoints[2], endpoints[3]:endpoints[4])] <- NA
S.x.hat_MD <- rep(NA, times = N)

for(j in 0:(N-1)){
  k.vec <- rep(NA,times = 6)
  for(k in 0:5){
    v_k <- insert(eig_vecs[,k+1], ats=c(rep(endpoints[1], times = endpoints[2] - endpoints[1] + 1),rep(endpoints[3], times = endpoints[4] - endpoints[3] + 1)))
    W.t <- v_k*X.t_missing
    inner.sum <- sum(W.t*exp(-complex(real = 0, imaginary = 1)*2*pi*t.n*j/N), na.rm = TRUE)
    k.vec[k + 1] <- abs(inner.sum)^2
  }
  S.x.hat_MD[j+1] <- mean(k.vec)
}


plot(log10(f.j), log10(S.x.hat_MD), type = "l", main = "Missing Data") #plot of multitaper spectral estimator

```




Now to compare them on the same plot:

```{r}

plot(log10(f.j), log10(S.x.hat), type = "l", main = "Full Data vs. Partial Data")
lines(log10(f.j), log10(S.x.hat_MD), col = "red")
legend(x = -1.8, y = 1.7, legend = c("Full Data MTSE", "Partial Data MTSE"), col = c("black", "red"), lty = 1)

```
The spectrum of an ARFIMA process is a well known relationship, we show the log-log relationship here: $\log S(f) = \log(\sigma_\epsilon^2) - 2d\log(2|\sin\pi f|)$.

For the data above, recall that $d = 0.4$ and $\sigma_\epsilon^2 = 1$, so we plot this relationship along with the spectral estimates above:

```{r}

plot(log10(f.j), log10(S.x.hat), type = "l", main = "Full Data vs. Partial Data", ylim = c(-1, 2.5))
lines(log10(f.j), log10(S.x.hat_MD), col = "red")
lines(log10(f.j), -2*d*log10(2*sin(pi*f.j)), col = "blue")
legend(x = -1.8, y = 2.2, legend = c("Full Data MTSE", "Partial Data MTSE", "Truth"), col = c("black", "red", "blue"), lty = 1)

```

The multitaper estimates look off by a constant--slope looks consistent with truth, need to investigate.


## Another Example






## Power Law Processes

In clock frequency stability analysis typically physicists will assume a certain power law process and then calculate an Allan Deviation based on that assumption. With spectral analysis, however, we can test these assumptions, do the same kinds of analyses that clock physicists do, and more.


### Linear Drift
(Reappraisal 1987)

Due to environmental and systemic factors, there could be linear drifts in fractional frequency data $\{y_t\}$, so we actually have data of the form: 

$$y_t' = a + bt + y_t $$

According to Reappraisal, while the two sample variance has ways of dealing with this, namely, to estimate $b$ by:
 $$\hat{b} = \frac{y_N' - y_1'}{N-1} $$ where $N$ is the number of data points. Then estimate $\sigma_y^2(y,\tau)$ by $$ \hat{y_t} = y_t' - \hat{b}t$$. This yields a downwardly biased estimator of $\sigma_y^2$ (see Fig. 2 of Reappraisal).
 
If we have access to a direct spectral estimate of possibly tapered data, however, we can more effectively remove this linear drift using differencing of the data which, in the spectral realm, equates to an application of a simple linear filter. 


### Fitting a line for a Power Law process
(Multitaper for Power Law 98)

Clock Data is often assumed to be from a power law process, which has spectrum of the form $S(f) = h_\alpha f^\alpha$ for $|f| \leq \frac{1}{2}$.

The goal then is to estimate $\alpha$ using this baseline assumption about the spectral form of the underlying process.

#### Two Sample Variance Technique

There is a well-known result (according to Reappraisal), that the two-sample variance is well approximated by $\frac{A_\alpha}{\tau^{\alpha + 1}}$ for $A_\alpha$ dependent on $\alpha$, but not $h_\alpha$.

For reasons outlined in more detail in Reappraisal..., we may use the regression model:

 $$\log(\hat{\sigma}_y^2(2;2^k)) = \log(A_\alpha) - (\alpha + 1)k\log(2) + \eta_k\ $$
for $k = 0,\ldots,p-1$ where  where the $\eta_k$ are error terms that do not meet the assumptions of OLS due to heteroskedasticity and they are correlated--to name just two. This means we can estimate $\alpha$ 


#### Spectral Technique

Using a spectral estimate $\hat{S(f_k})$, we can find $\alpha$ by using the following regression:

$$\log(\hat{S}(f_k)) = \log(h_\alpha) + \alpha \log(f_k) $$ for $k = 1, ..., M$

where $M = N/2$ and $f_k = k/N$. Here we more closely match the assumptions of classical regression and thus we can obtain estimates for $\alpha$ and $h_\alpha$ as well as meaningful uncertainty estimates.

### White Noise Example

We recreate the analysis done in "Reappraisal..." where we generate 1000 WN(0,1) processes (a spectrum for which we know $\alpha = 0$) and try both techniques.

```{r, echo = FALSE}

#We already know for WN(0,1), S_y(f) = 1

#1. Create some data: 1000 realizations of N=128 WN(0,1)
N <- 128
Y <- matrix(NA, nrow = 1000,ncol = 128)

for(i in 1:1000){
set.seed(i)
Y[i,] <- rnorm(N,mean = 0, sd = 1)
}

#2. Calculate AVAR estimates
AVAR.Y <- matrix(NA, nrow = 1000, ncol = 6)
for(i in 1:1000){
  AVAR.Y[i,] <- getAvars(N,Y[i,])$avarRes$avars
}

#3. Calculate S_y(f_k) estimates
Spec.Y <- matrix(NA, nrow = 1000, ncol = 64)
for(i in 1:1000){
  Spec.Y[i,] <- spec.pgram(Y[i,], plot = FALSE)$spec
}

#4. fit lines in log-log space to these estimates
v_k <- (0:5)*log(2)
alpha.ests_AVAR <- alpha.ests_spec <- rep(NA, times = 1000)

for(i in 1:1000){
 alpha.ests_AVAR[i] <-  -(lm(log(AVAR.Y[i,]) ~ v_k)$coefficients[2] + 1)
}

log_fk <- log(1:64/128)

for(i in 1:1000){
  alpha.ests_spec[i] <-  lm(log(Spec.Y[i,]) ~  log_fk)$coefficients[2] 
}


print(paste("AVAR alpha estimate: ", mean(alpha.ests_AVAR)))
print(paste("Spectrum alpha estimate: ", mean(alpha.ests_spec)))


```

This shows the bias of the two sample approach.

### Detection of Periodic Components
(Reappraisal 1987)



## Missing Data Example







